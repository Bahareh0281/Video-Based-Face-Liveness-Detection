{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f1af9ee62e44cc6af904d12480a42f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52b9e1612eb649338c7177d5226e1c23",
              "IPY_MODEL_8314fa1c999d4d28887283cedf16c36e",
              "IPY_MODEL_e98e8dd06ef7428289d45e492030e2ab"
            ],
            "layout": "IPY_MODEL_cca39e102af14e6db258933759a53e71"
          }
        },
        "52b9e1612eb649338c7177d5226e1c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8981626bf4041c88f19ae3d1a98efd7",
            "placeholder": "​",
            "style": "IPY_MODEL_864539a61efe4015b4b2eca64ff242c1",
            "value": "Downloading data: 100%"
          }
        },
        "8314fa1c999d4d28887283cedf16c36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_930256fb35b84a2fbae859d11ee4dce1",
            "max": 136678272,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6718113939f84d698e21ad85cc59891b",
            "value": 136678272
          }
        },
        "e98e8dd06ef7428289d45e492030e2ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67ff568b8a7648fbab54688f7f34ad7d",
            "placeholder": "​",
            "style": "IPY_MODEL_af79e8931e544a82a2e12ebd215f7e77",
            "value": " 137M/137M [00:01&lt;00:00, 157MB/s]"
          }
        },
        "cca39e102af14e6db258933759a53e71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8981626bf4041c88f19ae3d1a98efd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "864539a61efe4015b4b2eca64ff242c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "930256fb35b84a2fbae859d11ee4dce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6718113939f84d698e21ad85cc59891b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67ff568b8a7648fbab54688f7f34ad7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af79e8931e544a82a2e12ebd215f7e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "209f6b0782474092b92494ec70876b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f1d55199a36459ebff417854022a528",
              "IPY_MODEL_346a3f77435b4faa844d72a768f48e6e",
              "IPY_MODEL_38496baea3f84c109470a365551d5109"
            ],
            "layout": "IPY_MODEL_f01adbc7686146ee9915f8f9ef7b6910"
          }
        },
        "0f1d55199a36459ebff417854022a528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_628e6fc31b7e4f5b97fa9a8bcc85a870",
            "placeholder": "​",
            "style": "IPY_MODEL_3f0de2688700409aaeb42ad966c68e62",
            "value": "Generating train split: 100%"
          }
        },
        "346a3f77435b4faa844d72a768f48e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f6551d5918f4654b0a55e42559fdffe",
            "max": 6427,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0b0f1a2242640bb8df3eb90cd74fc77",
            "value": 6427
          }
        },
        "38496baea3f84c109470a365551d5109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_076058cc18e1408784c04aec89b9bdd7",
            "placeholder": "​",
            "style": "IPY_MODEL_ad5e87fcdabb41cb99eb3ce7cfab64a9",
            "value": " 6427/6427 [00:01&lt;00:00, 7598.53 examples/s]"
          }
        },
        "f01adbc7686146ee9915f8f9ef7b6910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "628e6fc31b7e4f5b97fa9a8bcc85a870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f0de2688700409aaeb42ad966c68e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f6551d5918f4654b0a55e42559fdffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0b0f1a2242640bb8df3eb90cd74fc77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "076058cc18e1408784c04aec89b9bdd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad5e87fcdabb41cb99eb3ce7cfab64a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "FkvBs2kkk0VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets --q"
      ],
      "metadata": {
        "id": "NCMWIuGakslU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7f4d69-5df7-4825-a09a-5d79233b4358"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "Itel1B0OktLk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset = load_dataset(\"Bahareh0281/liveness_images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "8f1af9ee62e44cc6af904d12480a42f2",
            "52b9e1612eb649338c7177d5226e1c23",
            "8314fa1c999d4d28887283cedf16c36e",
            "e98e8dd06ef7428289d45e492030e2ab",
            "cca39e102af14e6db258933759a53e71",
            "b8981626bf4041c88f19ae3d1a98efd7",
            "864539a61efe4015b4b2eca64ff242c1",
            "930256fb35b84a2fbae859d11ee4dce1",
            "6718113939f84d698e21ad85cc59891b",
            "67ff568b8a7648fbab54688f7f34ad7d",
            "af79e8931e544a82a2e12ebd215f7e77",
            "209f6b0782474092b92494ec70876b1d",
            "0f1d55199a36459ebff417854022a528",
            "346a3f77435b4faa844d72a768f48e6e",
            "38496baea3f84c109470a365551d5109",
            "f01adbc7686146ee9915f8f9ef7b6910",
            "628e6fc31b7e4f5b97fa9a8bcc85a870",
            "3f0de2688700409aaeb42ad966c68e62",
            "6f6551d5918f4654b0a55e42559fdffe",
            "c0b0f1a2242640bb8df3eb90cd74fc77",
            "076058cc18e1408784c04aec89b9bdd7",
            "ad5e87fcdabb41cb99eb3ce7cfab64a9"
          ]
        },
        "id": "6nlXJUhbkxKx",
        "outputId": "5ea35113-cf53-4812-f280-9b7df897ea57"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/137M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f1af9ee62e44cc6af904d12480a42f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/6427 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "209f6b0782474092b92494ec70876b1d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset['train'][7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W66msnCyk_tx",
        "outputId": "e97a7441-773e-4f7c-b414-0c488947528f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256>,\n",
              " 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Necessary Libraries"
      ],
      "metadata": {
        "id": "lMhDO8JIixJ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "URBYLMbzh7fL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage import measure\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction Functions"
      ],
      "metadata": {
        "id": "SNoHJHh8jESM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "radius = 3\n",
        "n_points = 8 * radius\n",
        "\n",
        "def compute_fourier_transform(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    f = np.fft.fft2(gray)\n",
        "    fshift = np.fft.fftshift(f)\n",
        "    magnitude_spectrum = 20 * np.log(np.abs(fshift))\n",
        "    return magnitude_spectrum\n",
        "\n",
        "def compute_lbp(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    lbp = local_binary_pattern(gray, n_points, radius, method=\"uniform\")\n",
        "    return lbp\n",
        "\n",
        "def compute_depth(image):\n",
        "    # به عنوان مثال از کانال آبی برای تخمین عمق استفاده می‌کنیم\n",
        "    depth = image[:, :, 2]\n",
        "    return depth\n",
        "\n",
        "def extract_statistical_features(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    mean = np.mean(gray)\n",
        "    std_dev = np.std(gray)\n",
        "    skewness = np.mean((gray - mean) ** 3) / (std_dev ** 3)\n",
        "    kurtosis = np.mean((gray - mean) ** 4) / (std_dev ** 4)\n",
        "    entropy = measure.shannon_entropy(gray)\n",
        "    return mean, std_dev, skewness, kurtosis, entropy"
      ],
      "metadata": {
        "id": "dot437z0jBhz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Input Images"
      ],
      "metadata": {
        "id": "Jsan8-dljK-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(Dataset['train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkl0BgNdtzNS",
        "outputId": "7ac187eb-2fce-45c9-e23b-1fe3511d0480"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6427"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_images(dataset, traget_size, num=0):\n",
        "    train_images_features = []\n",
        "    train_images_labels = []\n",
        "    if num == 0:\n",
        "        num = len(dataset['train'])\n",
        "\n",
        "    for i in range(num):\n",
        "        img = dataset['train'][i]['image']\n",
        "        if isinstance(img, Image.Image):\n",
        "            img = np.array(img)  # Convert PIL image to NumPy array\n",
        "\n",
        "            # Extract frequency features\n",
        "            magnitude_spectrum = compute_fourier_transform(img)\n",
        "            magnitude_spectrum_resized = cv2.resize(magnitude_spectrum, (traget_size, traget_size))\n",
        "\n",
        "            # Extract LBP features\n",
        "            lbp = compute_lbp(img)\n",
        "            lbp_hist, _ = np.histogram(lbp, bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
        "            lbp_hist_normalized = lbp_hist / lbp_hist.sum()\n",
        "            lbp_hist_resized = cv2.resize(lbp_hist_normalized.reshape(-1, 1), (traget_size, traget_size))\n",
        "\n",
        "            # Extract statistical features\n",
        "            mean, std_dev, skewness, kurtosis, entropy = extract_statistical_features(img)\n",
        "            statistical_features = np.array([mean, std_dev, skewness, kurtosis, entropy])\n",
        "            statistical_features_resized = cv2.resize(statistical_features.reshape(-1, 1), (traget_size, traget_size))\n",
        "\n",
        "            # Combine features into a 3D array\n",
        "            combined_features = np.stack([\n",
        "                magnitude_spectrum_resized,\n",
        "                lbp_hist_resized,\n",
        "                statistical_features_resized\n",
        "            ], axis=-1)\n",
        "\n",
        "            train_images_features.append(combined_features)\n",
        "            train_images_labels.append(dataset['train'][i]['label'])\n",
        "\n",
        "    return np.array(train_images_features), np.array(train_images_labels)"
      ],
      "metadata": {
        "id": "z87X257BthVT"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_features,  train_images_labels = process_images(Dataset, 64, 3000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up51-JBOi6K8",
        "outputId": "42422dfd-01e6-4443-8292-8a9735aad3ba"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-11f85dd407e5>:8: RuntimeWarning: divide by zero encountered in log\n",
            "  magnitude_spectrum = 20 * np.log(np.abs(fshift))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_images_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esqMUsDfs1Vz",
        "outputId": "08e9348e-1608-4a29-dfba-0f7cc52faa36"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C3fYXFByuPK",
        "outputId": "0ea70b6e-b2be-456b-dece-3fbc427b790d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_features[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVbEpCHpy196",
        "outputId": "45b8bbb1-a1e8-48ff-b238-4cc857c59062"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[9.98781304e+01, 1.70135498e-02, 1.23999863e+02],\n",
              "        [1.03112881e+02, 1.70135498e-02, 1.23999863e+02],\n",
              "        [1.00401371e+02, 1.70135498e-02, 1.23999863e+02],\n",
              "        ...,\n",
              "        [8.08424041e+01, 1.70135498e-02, 1.23999863e+02],\n",
              "        [8.49438029e+01, 1.70135498e-02, 1.23999863e+02],\n",
              "        [9.55299601e+01, 1.70135498e-02, 1.23999863e+02]],\n",
              "\n",
              "       [[7.85450649e+01, 1.65896416e-02, 1.23999863e+02],\n",
              "        [8.88281131e+01, 1.65896416e-02, 1.23999863e+02],\n",
              "        [8.47440767e+01, 1.65896416e-02, 1.23999863e+02],\n",
              "        ...,\n",
              "        [9.16315104e+01, 1.65896416e-02, 1.23999863e+02],\n",
              "        [9.06426121e+01, 1.65896416e-02, 1.23999863e+02],\n",
              "        [8.25498088e+01, 1.65896416e-02, 1.23999863e+02]],\n",
              "\n",
              "       [[9.15188864e+01, 1.50151253e-02, 1.23999863e+02],\n",
              "        [9.45883978e+01, 1.50151253e-02, 1.23999863e+02],\n",
              "        [9.23813503e+01, 1.50151253e-02, 1.23999863e+02],\n",
              "        ...,\n",
              "        [9.37271837e+01, 1.50151253e-02, 1.23999863e+02],\n",
              "        [9.23618173e+01, 1.50151253e-02, 1.23999863e+02],\n",
              "        [9.04500895e+01, 1.50151253e-02, 1.23999863e+02]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[8.18726194e+01, 1.72089338e-01, 6.84012221e+00],\n",
              "        [9.39470200e+01, 1.72089338e-01, 6.84012221e+00],\n",
              "        [8.42057294e+01, 1.72089338e-01, 6.84012221e+00],\n",
              "        ...,\n",
              "        [9.14947383e+01, 1.72089338e-01, 6.84012221e+00],\n",
              "        [7.99644254e+01, 1.72089338e-01, 6.84012221e+00],\n",
              "        [9.64360706e+01, 1.72089338e-01, 6.84012221e+00]],\n",
              "\n",
              "       [[7.67963766e+01, 2.15115786e-01, 6.84012221e+00],\n",
              "        [8.99967501e+01, 2.15115786e-01, 6.84012221e+00],\n",
              "        [8.08708981e+01, 2.15115786e-01, 6.84012221e+00],\n",
              "        ...,\n",
              "        [8.95057065e+01, 2.15115786e-01, 6.84012221e+00],\n",
              "        [8.59257870e+01, 2.15115786e-01, 6.84012221e+00],\n",
              "        [7.89247608e+01, 2.15115786e-01, 6.84012221e+00]],\n",
              "\n",
              "       [[9.62452804e+01, 2.26699829e-01, 6.84012221e+00],\n",
              "        [8.69844970e+01, 2.26699829e-01, 6.84012221e+00],\n",
              "        [9.12226090e+01, 2.26699829e-01, 6.84012221e+00],\n",
              "        ...,\n",
              "        [9.74845177e+01, 2.26699829e-01, 6.84012221e+00],\n",
              "        [9.76303721e+01, 2.26699829e-01, 6.84012221e+00],\n",
              "        [9.74363104e+01, 2.26699829e-01, 6.84012221e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_images_features[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBECxZD6zG0n",
        "outputId": "725c89da-6f5f-4d25-b8f3-510825fa0c81"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_images_features[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-vc9TiazIbY",
        "outputId": "b3077275-5b26-4034-bcb4-f8b0db11b4c9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split training dataset and prepare it for train process"
      ],
      "metadata": {
        "id": "5VY-vRmm7N6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert depth features to a numpy array\n",
        "features = np.array(train_images_features)\n",
        "labels = np.array(train_images_labels)\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, num_classes=2)\n",
        "y_test = to_categorical(y_test, num_classes=2)\n"
      ],
      "metadata": {
        "id": "aJZ792Fe0JLs"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create CNN Model and Train it"
      ],
      "metadata": {
        "id": "oBE5VM3g7XFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7x7f9i33lS4",
        "outputId": "428ed9d6-4e34-4013-943a-c50848a811c9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "60/60 [==============================] - 2s 10ms/step - loss: 4.3560 - accuracy: 0.7510 - val_loss: 0.4191 - val_accuracy: 0.8271\n",
            "Epoch 2/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.5129 - accuracy: 0.7875 - val_loss: 0.4281 - val_accuracy: 0.8271\n",
            "Epoch 3/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7943 - val_loss: 0.4047 - val_accuracy: 0.8229\n",
            "Epoch 4/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7964 - val_loss: 0.3992 - val_accuracy: 0.8271\n",
            "Epoch 5/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7974 - val_loss: 0.4384 - val_accuracy: 0.8313\n",
            "Epoch 6/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.8083 - val_loss: 0.3882 - val_accuracy: 0.8354\n",
            "Epoch 7/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.8068 - val_loss: 0.3867 - val_accuracy: 0.8375\n",
            "Epoch 8/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8188 - val_loss: 0.3909 - val_accuracy: 0.8500\n",
            "Epoch 9/20\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8161 - val_loss: 0.3748 - val_accuracy: 0.8458\n",
            "Epoch 10/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8297 - val_loss: 0.3929 - val_accuracy: 0.8458\n",
            "Epoch 11/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8297 - val_loss: 0.3957 - val_accuracy: 0.8479\n",
            "Epoch 12/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8323 - val_loss: 0.3923 - val_accuracy: 0.8458\n",
            "Epoch 13/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8328 - val_loss: 0.3963 - val_accuracy: 0.8333\n",
            "Epoch 14/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8396 - val_loss: 0.3646 - val_accuracy: 0.8583\n",
            "Epoch 15/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8328 - val_loss: 0.3690 - val_accuracy: 0.8562\n",
            "Epoch 16/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8391 - val_loss: 0.3804 - val_accuracy: 0.8354\n",
            "Epoch 17/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8286 - val_loss: 0.4174 - val_accuracy: 0.8250\n",
            "Epoch 18/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8172 - val_loss: 0.4055 - val_accuracy: 0.8292\n",
            "Epoch 19/20\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8349 - val_loss: 0.4170 - val_accuracy: 0.8458\n",
            "Epoch 20/20\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8448 - val_loss: 0.3575 - val_accuracy: 0.8625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate on dataset tests"
      ],
      "metadata": {
        "id": "z-VAc5m57ei2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DCO0A3o4IV2",
        "outputId": "c94bbc10-a73b-4cac-dbb0-b4545206d39e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8567\n",
            "Test Accuracy: 85.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load test videos"
      ],
      "metadata": {
        "id": "tfF_mfOt7ksY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "file_id = '1a5R5h05hCyw9PzIBhSjy2jLL3dSFy2xA'\n",
        "destination = '/content/dataset.zip'  # Path where the file will be saved\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', destination, quiet=False)\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(destination, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPgJ2aLO5MkB",
        "outputId": "3c3074a6-4285-4034-dc39-82f1723f8fe8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1a5R5h05hCyw9PzIBhSjy2jLL3dSFy2xA\n",
            "From (redirected): https://drive.google.com/uc?id=1a5R5h05hCyw9PzIBhSjy2jLL3dSFy2xA&confirm=t&uuid=ee7712b1-45cb-4343-8c30-e1e1b8d8956f\n",
            "To: /content/dataset.zip\n",
            "\n",
            "  0%|          | 0.00/377M [00:00<?, ?B/s]\u001b[A\n",
            "  0%|          | 1.57M/377M [00:00<00:24, 15.6MB/s]\u001b[A\n",
            "  4%|▍         | 16.8M/377M [00:00<00:03, 94.8MB/s]\u001b[A\n",
            "  9%|▉         | 35.1M/377M [00:00<00:02, 133MB/s] \u001b[A\n",
            " 14%|█▍        | 53.0M/377M [00:00<00:02, 150MB/s]\u001b[A\n",
            " 19%|█▉        | 70.8M/377M [00:00<00:01, 160MB/s]\u001b[A\n",
            " 24%|██▎       | 88.6M/377M [00:00<00:01, 166MB/s]\u001b[A\n",
            " 28%|██▊       | 106M/377M [00:00<00:01, 167MB/s] \u001b[A\n",
            " 31%|███       | 117M/377M [00:16<00:13, 19.1MB/s]\n",
            " 38%|███▊      | 142M/377M [00:01<00:02, 81.9MB/s]\u001b[A\n",
            " 41%|████      | 155M/377M [00:01<00:03, 57.5MB/s]\u001b[A\n",
            " 45%|████▍     | 168M/377M [00:02<00:04, 44.9MB/s]\u001b[A\n",
            " 49%|████▉     | 185M/377M [00:02<00:04, 42.0MB/s]\u001b[A\n",
            " 54%|█████▎    | 202M/377M [00:03<00:04, 40.0MB/s]\u001b[A\n",
            " 56%|█████▌    | 210M/377M [00:03<00:04, 39.8MB/s]\u001b[A\n",
            " 58%|█████▊    | 219M/377M [00:03<00:03, 39.6MB/s]\u001b[A\n",
            " 60%|██████    | 227M/377M [00:03<00:03, 40.0MB/s]\u001b[A\n",
            " 62%|██████▏   | 235M/377M [00:03<00:03, 38.7MB/s]\u001b[A\n",
            " 65%|██████▍   | 244M/377M [00:04<00:03, 39.8MB/s]\u001b[A\n",
            " 67%|██████▋   | 252M/377M [00:04<00:03, 39.6MB/s]\u001b[A\n",
            " 69%|██████▉   | 261M/377M [00:04<00:02, 39.7MB/s]\u001b[A\n",
            " 71%|███████▏  | 269M/377M [00:04<00:02, 39.5MB/s]\u001b[A\n",
            " 74%|███████▎  | 277M/377M [00:05<00:02, 37.6MB/s]\u001b[A\n",
            " 76%|███████▌  | 286M/377M [00:05<00:02, 40.7MB/s]\u001b[A\n",
            " 78%|███████▊  | 294M/377M [00:05<00:02, 38.3MB/s]\u001b[A\n",
            " 80%|████████  | 303M/377M [00:05<00:01, 39.6MB/s]\u001b[A\n",
            " 83%|████████▎ | 311M/377M [00:05<00:01, 38.6MB/s]\u001b[A\n",
            " 85%|████████▍ | 319M/377M [00:06<00:01, 37.8MB/s]\u001b[A\n",
            " 87%|████████▋ | 328M/377M [00:06<00:01, 36.7MB/s]\u001b[A\n",
            " 89%|████████▉ | 336M/377M [00:06<00:01, 38.7MB/s]\u001b[A\n",
            " 91%|█████████▏| 344M/377M [00:06<00:00, 37.4MB/s]\u001b[A\n",
            " 94%|█████████▎| 353M/377M [00:06<00:00, 39.8MB/s]\u001b[A\n",
            " 96%|█████████▌| 361M/377M [00:07<00:00, 35.5MB/s]\u001b[A\n",
            "100%|██████████| 377M/377M [00:07<00:00, 50.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate random frames from each video"
      ],
      "metadata": {
        "id": "Zy4f0V9B7osL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def extract_frames(video_path, save_path, label, test):\n",
        "    # Open the video file\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Select one random frame\n",
        "    random_frame = random.randint(0, frame_count - 1)\n",
        "\n",
        "    # Set the position of the video to the selected frame\n",
        "    video.set(cv2.CAP_PROP_POS_FRAMES, random_frame)\n",
        "    success, frame = video.read()\n",
        "\n",
        "    # If the frame was successfully read, save it\n",
        "    if success:\n",
        "        frame_path = os.path.join(save_path, f\"{label}_{random_frame}.jpg\")\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "\n",
        "        # Convert the frame to a PIL image\n",
        "        pil_image = Image.open(frame_path)\n",
        "\n",
        "        # Save the image and label to the dictionary\n",
        "        test.append({'image': pil_image, 'label': label})\n",
        "\n",
        "    # Release the video file\n",
        "    video.release()"
      ],
      "metadata": {
        "id": "rgdA0sFM4qgL"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "fake_test_videos_path = '/content/dataset/fake/test'\n",
        "real_test_videos_path = '/content/dataset/real/test'\n",
        "\n",
        "save_frames_path = '/content/extracted_frames2/test'\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(save_frames_path):\n",
        "    os.makedirs(save_frames_path)\n",
        "\n",
        "# Create a list to hold the dictionary entries\n",
        "test = []\n",
        "\n",
        "# Iterate over fake videos and extract frames\n",
        "for fake_video_file in os.listdir(fake_test_videos_path):\n",
        "    fake_video_path = os.path.join(fake_test_videos_path, fake_video_file)\n",
        "    extract_frames(fake_video_path, save_frames_path, 0, test)\n",
        "\n",
        "# Iterate over real videos and extract frames\n",
        "for real_video_file in os.listdir(real_test_videos_path):\n",
        "    real_video_path = os.path.join(real_test_videos_path, real_video_file)\n",
        "    extract_frames(real_video_path, save_frames_path, 1, test)"
      ],
      "metadata": {
        "id": "_bRG9QQu4rWX"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmkzr-laOxiV",
        "outputId": "17d0fb19-abdc-4139-db1c-2fc668511066"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract features from each frame"
      ],
      "metadata": {
        "id": "l-Y77Zij704f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_images_2(tests, traget_size):\n",
        "    test_images_features = []\n",
        "    test_images_labels = []\n",
        "\n",
        "\n",
        "    for i in range(len(tests)):\n",
        "        img = tests[i]['image']\n",
        "        if isinstance(img, Image.Image):\n",
        "            img = np.array(img)  # Convert PIL image to NumPy array\n",
        "\n",
        "            # Extract frequency features\n",
        "            magnitude_spectrum = compute_fourier_transform(img)\n",
        "            magnitude_spectrum_resized = cv2.resize(magnitude_spectrum, (traget_size, traget_size))\n",
        "\n",
        "            # Extract LBP features\n",
        "            lbp = compute_lbp(img)\n",
        "            lbp_hist, _ = np.histogram(lbp, bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
        "            lbp_hist_normalized = lbp_hist / lbp_hist.sum()\n",
        "            lbp_hist_resized = cv2.resize(lbp_hist_normalized.reshape(-1, 1), (traget_size, traget_size))\n",
        "\n",
        "            # Extract statistical features\n",
        "            mean, std_dev, skewness, kurtosis, entropy = extract_statistical_features(img)\n",
        "            statistical_features = np.array([mean, std_dev, skewness, kurtosis, entropy])\n",
        "            statistical_features_resized = cv2.resize(statistical_features.reshape(-1, 1), (traget_size, traget_size))\n",
        "\n",
        "            # Combine features into a 3D array\n",
        "            combined_features = np.stack([\n",
        "                magnitude_spectrum_resized,\n",
        "                lbp_hist_resized,\n",
        "                statistical_features_resized\n",
        "            ], axis=-1)\n",
        "\n",
        "            test_images_features.append(combined_features)\n",
        "            test_images_labels.append(tests[i]['label'])\n",
        "\n",
        "    return np.array(test_images_features), np.array(test_images_labels)\n"
      ],
      "metadata": {
        "id": "zgwrJgz74uKi"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract features from each frame and convert labels to one-hot form"
      ],
      "metadata": {
        "id": "rqtnp6tY77S4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_frames_features, test_frames_labels = process_images_2(test, 64)\n",
        "\n",
        "test_frames_labels = to_categorical(test_frames_labels, num_classes=2)"
      ],
      "metadata": {
        "id": "RkPimjUo6GW9"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_frames_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnJI1FEI91gH",
        "outputId": "cca8d134-03fc-433c-e6f2-6e390dc66f65"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_frames_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UPtdpMf-G3m",
        "outputId": "8b8665dc-9a51-43e0-f05d-7174625214d3"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate model on test set"
      ],
      "metadata": {
        "id": "z7UunJdx8FEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_frames_features, test_frames_labels)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlfFZ28Q6qbg",
        "outputId": "d825e186-9da3-4d1e-ff0e-79ff02da6518"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: 0.7118 - accuracy: 0.6562\n",
            "Test Accuracy: 65.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "\n",
        "y_pred_proba = model.predict(test_frames_features)\n",
        "predictions_for_frames = []\n",
        "# Output the prediction vector for each test image\n",
        "for idx, prediction_vector in enumerate(y_pred_proba):\n",
        "    print(f\"Prediction vector for test image {idx+1}: {prediction_vector}\")\n",
        "    predictions_for_frames.append((idx, prediction_vector))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivqBLZjo8w3S",
        "outputId": "1f2b5077-24e6-464c-9c2c-7133c38efaf1"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "Prediction vector for test image 1: [0.7098569  0.29014307]\n",
            "Prediction vector for test image 2: [0.9798766  0.02012343]\n",
            "Prediction vector for test image 3: [0.96451646 0.03548349]\n",
            "Prediction vector for test image 4: [0.5949487  0.40505132]\n",
            "Prediction vector for test image 5: [0.9814904  0.01850965]\n",
            "Prediction vector for test image 6: [0.7292483  0.27075174]\n",
            "Prediction vector for test image 7: [0.76867956 0.23132046]\n",
            "Prediction vector for test image 8: [0.75053465 0.24946532]\n",
            "Prediction vector for test image 9: [0.9711704  0.02882952]\n",
            "Prediction vector for test image 10: [0.96261144 0.03738854]\n",
            "Prediction vector for test image 11: [0.94295    0.05704992]\n",
            "Prediction vector for test image 12: [0.6117652 0.3882348]\n",
            "Prediction vector for test image 13: [0.8364334  0.16356662]\n",
            "Prediction vector for test image 14: [0.7385954  0.26140457]\n",
            "Prediction vector for test image 15: [0.9494574  0.05054265]\n",
            "Prediction vector for test image 16: [0.9771572  0.02284286]\n",
            "Prediction vector for test image 17: [0.63083625 0.36916372]\n",
            "Prediction vector for test image 18: [0.9008494  0.09915063]\n",
            "Prediction vector for test image 19: [0.98025197 0.01974806]\n",
            "Prediction vector for test image 20: [0.92725307 0.07274698]\n",
            "Prediction vector for test image 21: [0.9811344  0.01886555]\n",
            "Prediction vector for test image 22: [0.90658396 0.09341599]\n",
            "Prediction vector for test image 23: [0.7270929  0.27290708]\n",
            "Prediction vector for test image 24: [0.81883144 0.18116853]\n",
            "Prediction vector for test image 25: [0.64025545 0.35974458]\n",
            "Prediction vector for test image 26: [0.71017426 0.28982577]\n",
            "Prediction vector for test image 27: [0.93659925 0.06340071]\n",
            "Prediction vector for test image 28: [0.64681834 0.35318163]\n",
            "Prediction vector for test image 29: [0.22982813 0.7701719 ]\n",
            "Prediction vector for test image 30: [0.679355   0.32064494]\n",
            "Prediction vector for test image 31: [0.7683698 0.2316302]\n",
            "Prediction vector for test image 32: [0.5811873  0.41881266]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# InceptionV3\n"
      ],
      "metadata": {
        "id": "mpLtVfnvJiG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "from tensorflow.keras.preprocessing.image import load_img"
      ],
      "metadata": {
        "id": "QA_1aKxkJho1"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_features,  train_images_labels = process_images(Dataset, 75, 3000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGOI_-TkKfTJ",
        "outputId": "d2e2374d-726a-406e-9f2b-712aca838390"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 117M/377M [12:16<27:06, 159kB/s] \n",
            "<ipython-input-6-11f85dd407e5>:8: RuntimeWarning: divide by zero encountered in log\n",
            "  magnitude_spectrum = 20 * np.log(np.abs(fshift))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert depth features to a numpy array\n",
        "features2 = np.array(train_images_features)\n",
        "labels2 = np.array(train_images_labels)\n",
        "# Split the data into training and testing sets\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(features2, labels2, test_size=0.2, random_state=42)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train2 = to_categorical(y_train2, num_classes=2)\n",
        "y_test2 = to_categorical(y_test2, num_classes=2)"
      ],
      "metadata": {
        "id": "Cd3vNRGJKhES"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained model\n",
        "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(75, 75, 3))  # Exclude the top layer\n",
        "\n",
        "# Freeze the layers of the pre-trained model\n",
        "for layer in inception_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a global spatial average pooling layer\n",
        "x = inception_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "# Add a logistic layer with the number of classes you have (binary classification)\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# This is the model we will train\n",
        "model = Model(inputs=inception_model.input, outputs=predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPYJwhFfJuER",
        "outputId": "51434204-cc24-4a95-8454-67b510fa41a4"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train2, y_train2, epochs=10, batch_size=32, validation_data=(X_test2, y_test2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRmvLjIqMtC8",
        "outputId": "a6c1763a-bd2f-43e2-c792-1e5f51cbc1ac"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "75/75 [==============================] - 12s 70ms/step - loss: 10.6319 - accuracy: 0.7254 - val_loss: 4.1390 - val_accuracy: 0.5717\n",
            "Epoch 2/10\n",
            "75/75 [==============================] - 1s 18ms/step - loss: 1.6047 - accuracy: 0.7804 - val_loss: 1.3298 - val_accuracy: 0.8350\n",
            "Epoch 3/10\n",
            "75/75 [==============================] - 1s 19ms/step - loss: 1.1379 - accuracy: 0.7971 - val_loss: 3.1350 - val_accuracy: 0.4800\n",
            "Epoch 4/10\n",
            "75/75 [==============================] - 1s 19ms/step - loss: 1.6602 - accuracy: 0.7892 - val_loss: 0.5015 - val_accuracy: 0.8700\n",
            "Epoch 5/10\n",
            "75/75 [==============================] - 2s 27ms/step - loss: 0.9463 - accuracy: 0.7958 - val_loss: 1.7081 - val_accuracy: 0.8133\n",
            "Epoch 6/10\n",
            "75/75 [==============================] - 1s 18ms/step - loss: 0.7672 - accuracy: 0.8167 - val_loss: 0.8685 - val_accuracy: 0.8533\n",
            "Epoch 7/10\n",
            "75/75 [==============================] - 1s 18ms/step - loss: 0.4900 - accuracy: 0.8417 - val_loss: 0.7989 - val_accuracy: 0.6567\n",
            "Epoch 8/10\n",
            "75/75 [==============================] - 1s 19ms/step - loss: 0.4012 - accuracy: 0.8546 - val_loss: 0.4115 - val_accuracy: 0.8683\n",
            "Epoch 9/10\n",
            "75/75 [==============================] - 1s 18ms/step - loss: 0.4853 - accuracy: 0.8375 - val_loss: 0.6046 - val_accuracy: 0.7433\n",
            "Epoch 10/10\n",
            "75/75 [==============================] - 1s 20ms/step - loss: 0.4442 - accuracy: 0.8375 - val_loss: 0.7253 - val_accuracy: 0.8217\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c379c54ebf0>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze the layers of the pre-trained model\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "rS0J0WQ3MkgF"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train2, y_train2, epochs=10, batch_size=32, validation_data=(X_test2, y_test2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n8tiKJqJvbN",
        "outputId": "a9df9d3e-24b3-4b6f-f7ce-814eccedc1c5"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "75/75 [==============================] - 40s 86ms/step - loss: 0.5452 - accuracy: 0.7925 - val_loss: 1.8175 - val_accuracy: 0.8100\n",
            "Epoch 2/10\n",
            "75/75 [==============================] - 4s 55ms/step - loss: 0.3496 - accuracy: 0.8650 - val_loss: 1.6700 - val_accuracy: 0.8100\n",
            "Epoch 3/10\n",
            "75/75 [==============================] - 5s 67ms/step - loss: 0.2547 - accuracy: 0.9038 - val_loss: 1.6330 - val_accuracy: 0.8100\n",
            "Epoch 4/10\n",
            "75/75 [==============================] - 4s 54ms/step - loss: 0.2465 - accuracy: 0.9108 - val_loss: 0.5524 - val_accuracy: 0.8467\n",
            "Epoch 5/10\n",
            "75/75 [==============================] - 4s 55ms/step - loss: 0.2207 - accuracy: 0.9287 - val_loss: 0.7412 - val_accuracy: 0.8117\n",
            "Epoch 6/10\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.1640 - accuracy: 0.9504 - val_loss: 0.4944 - val_accuracy: 0.8167\n",
            "Epoch 7/10\n",
            "75/75 [==============================] - 4s 55ms/step - loss: 0.1528 - accuracy: 0.9425 - val_loss: 0.2576 - val_accuracy: 0.8817\n",
            "Epoch 8/10\n",
            "75/75 [==============================] - 4s 55ms/step - loss: 0.1447 - accuracy: 0.9542 - val_loss: 0.3994 - val_accuracy: 0.8050\n",
            "Epoch 9/10\n",
            "75/75 [==============================] - 5s 67ms/step - loss: 0.2858 - accuracy: 0.9013 - val_loss: 1.2220 - val_accuracy: 0.8100\n",
            "Epoch 10/10\n",
            "75/75 [==============================] - 4s 53ms/step - loss: 0.1750 - accuracy: 0.9408 - val_loss: 0.1973 - val_accuracy: 0.9217\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c3743d1aaa0>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test2, y_test2)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTHnm-WeJxAE",
        "outputId": "b786ca13-3e89-4976-9b88-7d4e7f7a82ff"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 1s 25ms/step - loss: 0.1973 - accuracy: 0.9217\n",
            "Test Loss: 0.19729502499103546, Test Accuracy: 0.92166668176651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_frames_features2, test_frames_labels2 = process_images_2(test, 75)\n",
        "test_frames_labels2 = to_categorical(test_frames_labels2, num_classes=2)"
      ],
      "metadata": {
        "id": "gCyzC8ARQntL"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_frames_features2, test_frames_labels2)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdOB21rzQuG1",
        "outputId": "85fcc715-c204-4cbb-dfa5-035944383f70"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 48ms/step - loss: 1.2868 - accuracy: 0.5938\n",
            "Test Accuracy: 59.38%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "\n",
        "y_pred_proba = model.predict(test_frames_features2)\n",
        "predictions_for_frames = []\n",
        "# Output the prediction vector for each test image\n",
        "for idx, prediction_vector in enumerate(y_pred_proba):\n",
        "    print(f\"Prediction vector for test image {idx+1}: {prediction_vector}\")\n",
        "    predictions_for_frames.append((idx, prediction_vector))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY3Taz9DUA4b",
        "outputId": "d0f52006-e1bb-4883-8f7f-26a1966bef72"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Prediction vector for test image 1: [0.9574484 0.0425516]\n",
            "Prediction vector for test image 2: [0.98669654 0.01330348]\n",
            "Prediction vector for test image 3: [0.9791821  0.02081785]\n",
            "Prediction vector for test image 4: [0.19328159 0.8067184 ]\n",
            "Prediction vector for test image 5: [0.97900987 0.02099015]\n",
            "Prediction vector for test image 6: [0.987206   0.01279405]\n",
            "Prediction vector for test image 7: [0.40649554 0.5935044 ]\n",
            "Prediction vector for test image 8: [0.90500516 0.09499477]\n",
            "Prediction vector for test image 9: [0.9377996  0.06220046]\n",
            "Prediction vector for test image 10: [0.9688701  0.03112992]\n",
            "Prediction vector for test image 11: [0.9831234  0.01687652]\n",
            "Prediction vector for test image 12: [0.98220485 0.0177952 ]\n",
            "Prediction vector for test image 13: [0.9722124  0.02778759]\n",
            "Prediction vector for test image 14: [0.6606057 0.3393943]\n",
            "Prediction vector for test image 15: [0.45547906 0.5445209 ]\n",
            "Prediction vector for test image 16: [0.971383   0.02861698]\n",
            "Prediction vector for test image 17: [0.93393624 0.06606369]\n",
            "Prediction vector for test image 18: [0.9833245  0.01667542]\n",
            "Prediction vector for test image 19: [0.98410404 0.01589594]\n",
            "Prediction vector for test image 20: [0.9634175  0.03658254]\n",
            "Prediction vector for test image 21: [0.9806666  0.01933342]\n",
            "Prediction vector for test image 22: [0.98035437 0.01964559]\n",
            "Prediction vector for test image 23: [0.95399696 0.04600297]\n",
            "Prediction vector for test image 24: [0.9708147  0.02918529]\n",
            "Prediction vector for test image 25: [0.10827685 0.89172316]\n",
            "Prediction vector for test image 26: [0.97198    0.02802004]\n",
            "Prediction vector for test image 27: [0.974857   0.02514308]\n",
            "Prediction vector for test image 28: [0.97887987 0.02112017]\n",
            "Prediction vector for test image 29: [0.15699135 0.84300864]\n",
            "Prediction vector for test image 30: [0.9803868 0.0196132]\n",
            "Prediction vector for test image 31: [0.96898437 0.03101563]\n",
            "Prediction vector for test image 32: [0.97269213 0.02730784]\n"
          ]
        }
      ]
    }
  ]
}