{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download the videos dataset from [Google Drive](https://drive.google.com/file/d/1LU0gdV3p1ObZ7x7hKgsF-ppyt4-nJbeK/view?usp=sharing)"
      ],
      "metadata": {
        "id": "VebhQwE1w81Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE7UR8tvsTWo",
        "outputId": "ea949371-f5ee-4ee7-ce97-9764565af738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.15.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.6.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "file_id = '1LU0gdV3p1ObZ7x7hKgsF-ppyt4-nJbeK'\n",
        "destination = '/content/dataset.zip'  # Path where the file will be saved\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', destination, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "tWNNAc7Iv4mH",
        "outputId": "d9518c63-0cfe-46eb-9579-b009d4d95a06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1LU0gdV3p1ObZ7x7hKgsF-ppyt4-nJbeK\n",
            "From (redirected): https://drive.google.com/uc?id=1LU0gdV3p1ObZ7x7hKgsF-ppyt4-nJbeK&confirm=t&uuid=dec7b0e0-3430-45cd-aa17-2949bc69989f\n",
            "To: /content/dataset.zip\n",
            "100%|██████████| 229M/229M [00:01<00:00, 122MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(destination, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset')"
      ],
      "metadata": {
        "id": "Xr0ZHsYWw4Hm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dividing the Videos into frames"
      ],
      "metadata": {
        "id": "7Y0mq1gKxuVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "WNyrs7Mgxt-H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the directories containing the fake and real videos\n",
        "fake_videos_path = '/content/dataset/fake'\n",
        "real_videos_path = '/content/dataset/real'\n",
        "\n",
        "# Directories to save the frames\n",
        "fake_frames_dir = '/content/images/fake'\n",
        "real_frames_dir = '/content/images/real'\n",
        "os.makedirs(fake_frames_dir, exist_ok=True)\n",
        "os.makedirs(real_frames_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "dmS9Ubf0zP0d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames_from_videos(videos_path, frames_dir, label):\n",
        "    # Get all .mp4 files in the directory\n",
        "    video_files = glob(os.path.join(videos_path, '*.mp4'))\n",
        "\n",
        "    for video_file in video_files:\n",
        "        # Open the video file\n",
        "        cap = cv2.VideoCapture(video_file)\n",
        "        video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
        "\n",
        "        frame_count = 0\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Save the frame as an image file\n",
        "            frame_path = os.path.join(frames_dir, f'{label}_{video_name}_frame_{frame_count:04d}.jpg')\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        # Release the video capture object\n",
        "        cap.release()\n",
        "        print(f'Total frames extracted from {video_file}: {frame_count}')\n"
      ],
      "metadata": {
        "id": "v7Fm4m_5zQbt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract frames from fake videos\n",
        "extract_frames_from_videos(fake_videos_path, fake_frames_dir, 'fake')\n",
        "\n",
        "# Extract frames from real videos\n",
        "extract_frames_from_videos(real_videos_path, real_frames_dir, 'real')\n",
        "\n",
        "print('Frame extraction completed.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLZUXuRxzX7O",
        "outputId": "bc108a0e-f6aa-419a-e28f-356e0e9a3f5e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total frames extracted from /content/dataset/fake/fake_18.mp4: 272\n",
            "Total frames extracted from /content/dataset/fake/fake_17.mp4: 785\n",
            "Total frames extracted from /content/dataset/fake/fake_3.mp4: 108\n",
            "Total frames extracted from /content/dataset/fake/fake_21.mp4: 342\n",
            "Total frames extracted from /content/dataset/fake/fake_16.mp4: 151\n",
            "Total frames extracted from /content/dataset/fake/fake_25.mp4: 123\n",
            "Total frames extracted from /content/dataset/fake/fake_6.mp4: 97\n",
            "Total frames extracted from /content/dataset/fake/fake_10.mp4: 62\n",
            "Total frames extracted from /content/dataset/fake/fake_23.mp4: 191\n",
            "Total frames extracted from /content/dataset/fake/fake_5.mp4: 86\n",
            "Total frames extracted from /content/dataset/fake/fake_8.mp4: 55\n",
            "Total frames extracted from /content/dataset/fake/fake_28.mp4: 404\n",
            "Total frames extracted from /content/dataset/fake/fake_22.mp4: 201\n",
            "Total frames extracted from /content/dataset/fake/fake_24.mp4: 304\n",
            "Total frames extracted from /content/dataset/fake/fake_20.mp4: 461\n",
            "Total frames extracted from /content/dataset/fake/fake_7.mp4: 97\n",
            "Total frames extracted from /content/dataset/fake/fake_26.mp4: 186\n",
            "Total frames extracted from /content/dataset/fake/fake_4.mp4: 193\n",
            "Total frames extracted from /content/dataset/fake/fake_11.mp4: 68\n",
            "Total frames extracted from /content/dataset/fake/fake_29.mp4: 304\n",
            "Total frames extracted from /content/dataset/fake/fake_15.mp4: 94\n",
            "Total frames extracted from /content/dataset/fake/fake_12.mp4: 194\n",
            "Total frames extracted from /content/dataset/fake/fake_9.mp4: 75\n",
            "Total frames extracted from /content/dataset/fake/fake_14.mp4: 70\n",
            "Total frames extracted from /content/dataset/fake/fake_13.mp4: 129\n",
            "Total frames extracted from /content/dataset/fake/fake_27.mp4: 270\n",
            "Total frames extracted from /content/dataset/fake/fake_2.mp4: 71\n",
            "Total frames extracted from /content/dataset/fake/fake_19.mp4: 766\n",
            "Total frames extracted from /content/dataset/fake/fake_1.mp4: 82\n",
            "Total frames extracted from /content/dataset/real/real_1.mp4: 233\n",
            "Total frames extracted from /content/dataset/real/real_14.mp4: 83\n",
            "Total frames extracted from /content/dataset/real/real_26.mp4: 227\n",
            "Total frames extracted from /content/dataset/real/real_23.mp4: 81\n",
            "Total frames extracted from /content/dataset/real/real_17.mp4: 122\n",
            "Total frames extracted from /content/dataset/real/real_6.mp4: 65\n",
            "Total frames extracted from /content/dataset/real/real_25.mp4: 77\n",
            "Total frames extracted from /content/dataset/real/real_33.mp4: 1335\n",
            "Total frames extracted from /content/dataset/real/real_13.mp4: 108\n",
            "Total frames extracted from /content/dataset/real/real_9.mp4: 54\n",
            "Total frames extracted from /content/dataset/real/real_21.mp4: 50\n",
            "Total frames extracted from /content/dataset/real/real_7.mp4: 110\n",
            "Total frames extracted from /content/dataset/real/real_31.mp4: 2086\n",
            "Total frames extracted from /content/dataset/real/real_24.mp4: 432\n",
            "Total frames extracted from /content/dataset/real/real_18.mp4: 101\n",
            "Total frames extracted from /content/dataset/real/real_20.mp4: 89\n",
            "Total frames extracted from /content/dataset/real/real_28.mp4: 2262\n",
            "Total frames extracted from /content/dataset/real/real_34.mp4: 1848\n",
            "Total frames extracted from /content/dataset/real/real_11.mp4: 138\n",
            "Total frames extracted from /content/dataset/real/real_8.mp4: 76\n",
            "Total frames extracted from /content/dataset/real/real_5.mp4: 76\n",
            "Total frames extracted from /content/dataset/real/real_22.mp4: 2977\n",
            "Total frames extracted from /content/dataset/real/real_32.mp4: 1539\n",
            "Total frames extracted from /content/dataset/real/real_29.mp4: 814\n",
            "Total frames extracted from /content/dataset/real/real_27.mp4: 3815\n",
            "Total frames extracted from /content/dataset/real/real_2.mp4: 77\n",
            "Total frames extracted from /content/dataset/real/real_12.mp4: 78\n",
            "Total frames extracted from /content/dataset/real/real_19.mp4: 115\n",
            "Total frames extracted from /content/dataset/real/real_30.mp4: 1603\n",
            "Total frames extracted from /content/dataset/real/real_3.mp4: 235\n",
            "Total frames extracted from /content/dataset/real/real_10.mp4: 164\n",
            "Total frames extracted from /content/dataset/real/real_35.mp4: 927\n",
            "Frame extraction completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the directory to zip and the output zip file path\n",
        "directory_to_zip = '/content/images'\n",
        "output_zip_path = '/content/images'\n",
        "\n",
        "# Create a zip file of the directory\n",
        "shutil.make_archive(output_zip_path, 'zip', directory_to_zip)\n",
        "\n",
        "print(f'Zip file created: {output_zip_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGoAvCsV4b16",
        "outputId": "16ac8b84-c943-4e55-e506-f62eba260f35"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file created: /content/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Put Dataset in Hugging Face"
      ],
      "metadata": {
        "id": "zupeOilp5hmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets --q"
      ],
      "metadata": {
        "id": "AlFnly3O5l47"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "from datasets.filesystems import S3FileSystem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "spgYWiXb6WNU",
        "outputId": "51f05a07-c3dd-47e8-8051-1c82e3e03424"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'S3FileSystem' from 'datasets.filesystems' (/usr/local/lib/python3.10/dist-packages/datasets/filesystems/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2409d99c726b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilesystems\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS3FileSystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'S3FileSystem' from 'datasets.filesystems' (/usr/local/lib/python3.10/dist-packages/datasets/filesystems/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}